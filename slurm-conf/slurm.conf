# slurm.conf file generated by configurator easy.html.
# Put this file on all nodes of your cluster.
# See the slurm.conf man page for more information.
#
ControlMachine=PiTech
ControlAddr=10.244.1.23
# 
#MailProg=/bin/mail 
MpiDefault=none
#MpiParams=ports=#-# 
ProctrackType=proctrack/pgid
ReturnToService=1
SlurmctldPidFile=/var/run/slurm-llnl/slurmctld.pid
#SlurmctldPort=6817 
SlurmdPidFile=/var/run/slurm-llnl/slurmd.pid
#SlurmdPort=6818 
SlurmdSpoolDir=/var/lib/slurm-llnl/slurmd
SlurmUser=slurm
#SlurmdUser=root 
StateSaveLocation=/var/lib/slurm-llnl/slurmctld
SwitchType=switch/none
TaskPlugin=task/none
# 
# 
# TIMERS 
#KillWait=30 
#MinJobAge=300 
#SlurmctldTimeout=120 
#SlurmdTimeout=300 
# 
# 
# SCHEDULING 
FastSchedule=1
SchedulerType=sched/backfill
#SchedulerPort=7321 
#SelectType=select/linear
SelectType=select/cons_res
SelectTypeParameters=CR_CPU
# 
# 
# LOGGING AND ACCOUNTING 
AccountingStorageType=accounting_storage/none
#AccountingStorageType=1
#AccountingStorageLoc=/home/
ClusterName=cluster
#JobAcctGatherFrequency=30 
JobAcctGatherType=jobacct_gather/none
#SlurmctldDebug=3 
SlurmctldLogFile=/var/log/slurm-llnl/slurmctld.log
#SlurmdDebug=3 
SlurmdLogFile=/var/log/slurm-llnl/slurmd.log
# 
# 
# COMPUTE NODES 
# Config from dome NodeName=slurm-worker NodeAddr=10.244.1.19 CPUS=2 RealMemory=3000 CoresPerSocket=1 ThreadsPerCore=2 State=UNKNOWN
NodeName=slurm-worker-cs0 NodeAddr=10.244.1.25 CPUs=56 Boards=1 SocketsPerBoard=2 CoresPerSocket=14 ThreadsPerCore=2 RealMemory=60000 TmpDisk=900000
NodeName=slurm-worker-cs1 NodeAddr=10.244.2.4 CPUs=56 Boards=1 SocketsPerBoard=2 CoresPerSocket=14 ThreadsPerCore=2 RealMemory=60000 TmpDisk=900000
NodeName=slurm-worker-cs2 NodeAddr=10.244.3.4 CPUs=56 Boards=1 SocketsPerBoard=2 CoresPerSocket=14 ThreadsPerCore=2 RealMemory=60000 TmpDisk=900000
NodeName=slurm-worker-cs3 NodeAddr=10.244.4.3 CPUs=56 Boards=1 SocketsPerBoard=2 CoresPerSocket=14 ThreadsPerCore=2 RealMemory=60000 TmpDisk=900000
NodeName=slurm-worker-cs4 NodeAddr=10.244.5.2 CPUs=56 Boards=1 SocketsPerBoard=2 CoresPerSocket=14 ThreadsPerCore=2 RealMemory=60000 TmpDisk=900000
NodeName=slurm-worker-gs0 NodeAddr=10.244.6.2 CPUs=48 Boards=1 SocketsPerBoard=2 CoresPerSocket=12 ThreadsPerCore=2 RealMemory=230000 TmpDisk=900000


PartitionName=main Nodes=slurm-worker-cs[0-4] MaxTime=INFINITE State=UP
PartitionName=gpu Nodes=slurm-worker-gs0 MaxTime=INFINITE State=UP

